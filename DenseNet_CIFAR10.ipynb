{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DenseNet_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "493084c6d713499d9517aebeae63d0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be7cf30e33d0487291f8cd9ef864e7ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c40b27f7346441d390901f385aa37597",
              "IPY_MODEL_f2b653dfc9c74806a95ed11d76b1d22d",
              "IPY_MODEL_77c6658b292b45979f7d2f56477b41b7"
            ]
          }
        },
        "be7cf30e33d0487291f8cd9ef864e7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c40b27f7346441d390901f385aa37597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4309c6fdb0fb4072adb754f48bd91549",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc4590d9a9ec4f7aaf0d835f39a7dfdc"
          }
        },
        "f2b653dfc9c74806a95ed11d76b1d22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa4a0c68565f4d89aca3b92302a775e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_415ffe8f06f84f128058d0d3c2cafa4b"
          }
        },
        "77c6658b292b45979f7d2f56477b41b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b813028435042a0b8272f54e9fb936e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 50330608.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cd459bbe1694856b4bbfb74c11a74d0"
          }
        },
        "4309c6fdb0fb4072adb754f48bd91549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc4590d9a9ec4f7aaf0d835f39a7dfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa4a0c68565f4d89aca3b92302a775e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "415ffe8f06f84f128058d0d3c2cafa4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b813028435042a0b8272f54e9fb936e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cd459bbe1694856b4bbfb74c11a74d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongwon18/DenseNet_CIFAR10/blob/main/DenseNet_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suPWWhI7w9f_"
      },
      "source": [
        "- Copyright 2021. Dongwon Kim All rights reserved.\n",
        "- File name : DenseNet_CIFAR10.ipynb\n",
        "- Written by Dongwon Kim\n",
        "    \n",
        "- DenseNet\n",
        "    - build, train DenseNet\n",
        "    - test the model with CIFAR10 dataset to get accuracy over than 93%\n",
        "- Modificatoin history\n",
        "    - written by Dongwon Kim on Oct 2, 2021\n",
        "\n",
        "- using Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk0PuiSudwMc"
      },
      "source": [
        "#1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVT39mj9wzV1"
      },
      "source": [
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from google.colab import files\n",
        "from torchsummary import summary\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLJAJIn3xUSH"
      },
      "source": [
        "[reference](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
        "- image: 3 x 32 x32\n",
        "- total 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "493084c6d713499d9517aebeae63d0ca",
            "be7cf30e33d0487291f8cd9ef864e7ad",
            "c40b27f7346441d390901f385aa37597",
            "f2b653dfc9c74806a95ed11d76b1d22d",
            "77c6658b292b45979f7d2f56477b41b7",
            "4309c6fdb0fb4072adb754f48bd91549",
            "fc4590d9a9ec4f7aaf0d835f39a7dfdc",
            "aa4a0c68565f4d89aca3b92302a775e0",
            "415ffe8f06f84f128058d0d3c2cafa4b",
            "2b813028435042a0b8272f54e9fb936e",
            "3cd459bbe1694856b4bbfb74c11a74d0"
          ]
        },
        "id": "XEPULc0YxEh7",
        "outputId": "62d75f5f-c927-42ee-ca8d-e97cac20088f"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root = './',\n",
        "    download = True,\n",
        "    train = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root = './',\n",
        "    download = True,\n",
        "    train = False,\n",
        "    transform = transform\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "493084c6d713499d9517aebeae63d0ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkemwvfrycZA",
        "outputId": "519d565d-2a80-4615-e80f-003a6d748fe3"
      },
      "source": [
        "print(train_dataset.data.shape, len(train_dataset.targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZAuAGufzj5x",
        "outputId": "5def61f2-941c-4ccd-c5ad-d60fa14fbc23"
      },
      "source": [
        "print(test_dataset.data.shape, len(test_dataset.targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3) 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022eR7r8xkNA"
      },
      "source": [
        "tr_index, val_index = train_test_split(list(range(len(train_dataset))), test_size = 0.1, shuffle=True, stratify = train_dataset.targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTrTuoAsxlGK"
      },
      "source": [
        "tr_sampler= SubsetRandomSampler(tr_index)\n",
        "val_sampler = SubsetRandomSampler(val_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Vnd6gF0a8W"
      },
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers = 0,\n",
        "    sampler = tr_sampler\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers = 0,\n",
        "    sampler = val_sampler\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers = 0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzu75SFM0t06"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMNrRTXt9NFv"
      },
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_plane, growth_rate):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_plane)\n",
        "        self.conv1 = nn.Conv2d(in_plane, 4*growth_rate, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size = 3, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        return torch.cat([out, x], 1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GPI9F1yByAD"
      },
      "source": [
        "class TransitionBlock(nn.Module):\n",
        "    def __init__(self, in_plane, out_plane):\n",
        "        super(TransitionBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_plane)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_plane, out_plane, kernel_size=1, stride=1, bias=False)\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.relu(self.bn1(x)))       \n",
        "\n",
        "        return F.avg_pool2d(out, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMZaMu1CwHS"
      },
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, block=BottleneckBlock, growth_rate=12, num_classes=10, reduction=0.5):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "\n",
        "        in_plane = 2 * growth_rate\n",
        "        self.conv1 = nn.Conv2d(3, in_plane, kernel_size = 3, padding=1, bias=False)\n",
        "\n",
        "        # 1st Dense & Transition\n",
        "        self.dense1 = self.make_dense_block(block, in_plane, 6)\n",
        "        in_plane += 6 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans1 = TransitionBlock(in_plane, out_plane)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 2nd Dense & Transition\n",
        "        self.dense2 = self.make_dense_block(block, in_plane, 12)\n",
        "        in_plane += 12 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans2 = TransitionBlock(in_plane, out_plane)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 3rd Dense & Transition\n",
        "        self.dense3 = self.make_dense_block(block, in_plane, 24)\n",
        "        in_plane += 24 * growth_rate\n",
        "        out_plane = int(math.floor(in_plane * reduction))\n",
        "        self.trans3 = TransitionBlock(in_plane, out_plane)\n",
        "        in_plane = out_plane\n",
        "\n",
        "        # 4th Dense\n",
        "        self.dense4 = self.make_dense_block(block, in_plane, 16)\n",
        "        in_plane += 16 * growth_rate\n",
        "        \n",
        "        self.bn = nn.BatchNorm2d(in_plane)\n",
        "        self.fc = nn.Linear(in_plane, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "       \n",
        "\n",
        "    def make_dense_block(self, block, in_plane, nblock):\n",
        "        layers=[]\n",
        "        for i in range(nblock):\n",
        "            layers.append(block(in_plane, self.growth_rate))\n",
        "            in_plane += self.growth_rate\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 32 x 32\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        # 32 x 32\n",
        "        out = self.dense1(out)\n",
        "        out = self.trans1(out) # 32 -> 16\n",
        "        \n",
        "        # 16 x 16\n",
        "        out = self.dense2(out)\n",
        "        out = self.trans2(out) # 16 -> 8\n",
        "        \n",
        "        # 8 x 8\n",
        "        out = self.dense3(out)\n",
        "        out = self.trans3(out) # 8 -> 4\n",
        "\n",
        "        out = self.dense4(out)\n",
        "\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HYIla_ZMQ32"
      },
      "source": [
        "model = DenseNet()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMK5LWzbQPMQ",
        "outputId": "f2a1d675-c0ca-44cf-e77b-6fa44749c44c"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (dense1): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans1): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense2): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans2): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense3): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (trans3): TransitionBlock(\n",
              "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dense4): Sequential(\n",
              "    (0): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(300, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(312, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(324, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(336, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(348, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(360, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): BottleneckBlock(\n",
              "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(372, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc): Linear(in_features=384, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOG0d9CBNRR_",
        "outputId": "f3be8310-ee4d-4f22-b125-a506c7336337"
      },
      "source": [
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 32, 32]             648\n",
            "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
            "              ReLU-3           [-1, 24, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              ReLU-6           [-1, 48, 32, 32]               0\n",
            "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
            "   BottleneckBlock-8           [-1, 36, 32, 32]               0\n",
            "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
            "             ReLU-10           [-1, 36, 32, 32]               0\n",
            "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
            "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
            "             ReLU-13           [-1, 48, 32, 32]               0\n",
            "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-15           [-1, 48, 32, 32]               0\n",
            "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
            "             ReLU-17           [-1, 48, 32, 32]               0\n",
            "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
            "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
            "             ReLU-20           [-1, 48, 32, 32]               0\n",
            "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-22           [-1, 60, 32, 32]               0\n",
            "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
            "             ReLU-24           [-1, 60, 32, 32]               0\n",
            "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
            "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
            "             ReLU-27           [-1, 48, 32, 32]               0\n",
            "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-29           [-1, 72, 32, 32]               0\n",
            "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
            "             ReLU-31           [-1, 72, 32, 32]               0\n",
            "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
            "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
            "             ReLU-34           [-1, 48, 32, 32]               0\n",
            "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-36           [-1, 84, 32, 32]               0\n",
            "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
            "             ReLU-38           [-1, 84, 32, 32]               0\n",
            "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
            "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
            "             ReLU-41           [-1, 48, 32, 32]               0\n",
            "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
            "  BottleneckBlock-43           [-1, 96, 32, 32]               0\n",
            "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
            "             ReLU-45           [-1, 96, 32, 32]               0\n",
            "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
            "  TransitionBlock-47           [-1, 48, 16, 16]               0\n",
            "      BatchNorm2d-48           [-1, 48, 16, 16]              96\n",
            "             ReLU-49           [-1, 48, 16, 16]               0\n",
            "           Conv2d-50           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-51           [-1, 48, 16, 16]              96\n",
            "             ReLU-52           [-1, 48, 16, 16]               0\n",
            "           Conv2d-53           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-54           [-1, 60, 16, 16]               0\n",
            "      BatchNorm2d-55           [-1, 60, 16, 16]             120\n",
            "             ReLU-56           [-1, 60, 16, 16]               0\n",
            "           Conv2d-57           [-1, 48, 16, 16]           2,880\n",
            "      BatchNorm2d-58           [-1, 48, 16, 16]              96\n",
            "             ReLU-59           [-1, 48, 16, 16]               0\n",
            "           Conv2d-60           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-61           [-1, 72, 16, 16]               0\n",
            "      BatchNorm2d-62           [-1, 72, 16, 16]             144\n",
            "             ReLU-63           [-1, 72, 16, 16]               0\n",
            "           Conv2d-64           [-1, 48, 16, 16]           3,456\n",
            "      BatchNorm2d-65           [-1, 48, 16, 16]              96\n",
            "             ReLU-66           [-1, 48, 16, 16]               0\n",
            "           Conv2d-67           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-68           [-1, 84, 16, 16]               0\n",
            "      BatchNorm2d-69           [-1, 84, 16, 16]             168\n",
            "             ReLU-70           [-1, 84, 16, 16]               0\n",
            "           Conv2d-71           [-1, 48, 16, 16]           4,032\n",
            "      BatchNorm2d-72           [-1, 48, 16, 16]              96\n",
            "             ReLU-73           [-1, 48, 16, 16]               0\n",
            "           Conv2d-74           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-75           [-1, 96, 16, 16]               0\n",
            "      BatchNorm2d-76           [-1, 96, 16, 16]             192\n",
            "             ReLU-77           [-1, 96, 16, 16]               0\n",
            "           Conv2d-78           [-1, 48, 16, 16]           4,608\n",
            "      BatchNorm2d-79           [-1, 48, 16, 16]              96\n",
            "             ReLU-80           [-1, 48, 16, 16]               0\n",
            "           Conv2d-81           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-82          [-1, 108, 16, 16]               0\n",
            "      BatchNorm2d-83          [-1, 108, 16, 16]             216\n",
            "             ReLU-84          [-1, 108, 16, 16]               0\n",
            "           Conv2d-85           [-1, 48, 16, 16]           5,184\n",
            "      BatchNorm2d-86           [-1, 48, 16, 16]              96\n",
            "             ReLU-87           [-1, 48, 16, 16]               0\n",
            "           Conv2d-88           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-89          [-1, 120, 16, 16]               0\n",
            "      BatchNorm2d-90          [-1, 120, 16, 16]             240\n",
            "             ReLU-91          [-1, 120, 16, 16]               0\n",
            "           Conv2d-92           [-1, 48, 16, 16]           5,760\n",
            "      BatchNorm2d-93           [-1, 48, 16, 16]              96\n",
            "             ReLU-94           [-1, 48, 16, 16]               0\n",
            "           Conv2d-95           [-1, 12, 16, 16]           5,184\n",
            "  BottleneckBlock-96          [-1, 132, 16, 16]               0\n",
            "      BatchNorm2d-97          [-1, 132, 16, 16]             264\n",
            "             ReLU-98          [-1, 132, 16, 16]               0\n",
            "           Conv2d-99           [-1, 48, 16, 16]           6,336\n",
            "     BatchNorm2d-100           [-1, 48, 16, 16]              96\n",
            "            ReLU-101           [-1, 48, 16, 16]               0\n",
            "          Conv2d-102           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-103          [-1, 144, 16, 16]               0\n",
            "     BatchNorm2d-104          [-1, 144, 16, 16]             288\n",
            "            ReLU-105          [-1, 144, 16, 16]               0\n",
            "          Conv2d-106           [-1, 48, 16, 16]           6,912\n",
            "     BatchNorm2d-107           [-1, 48, 16, 16]              96\n",
            "            ReLU-108           [-1, 48, 16, 16]               0\n",
            "          Conv2d-109           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-110          [-1, 156, 16, 16]               0\n",
            "     BatchNorm2d-111          [-1, 156, 16, 16]             312\n",
            "            ReLU-112          [-1, 156, 16, 16]               0\n",
            "          Conv2d-113           [-1, 48, 16, 16]           7,488\n",
            "     BatchNorm2d-114           [-1, 48, 16, 16]              96\n",
            "            ReLU-115           [-1, 48, 16, 16]               0\n",
            "          Conv2d-116           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-117          [-1, 168, 16, 16]               0\n",
            "     BatchNorm2d-118          [-1, 168, 16, 16]             336\n",
            "            ReLU-119          [-1, 168, 16, 16]               0\n",
            "          Conv2d-120           [-1, 48, 16, 16]           8,064\n",
            "     BatchNorm2d-121           [-1, 48, 16, 16]              96\n",
            "            ReLU-122           [-1, 48, 16, 16]               0\n",
            "          Conv2d-123           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-124          [-1, 180, 16, 16]               0\n",
            "     BatchNorm2d-125          [-1, 180, 16, 16]             360\n",
            "            ReLU-126          [-1, 180, 16, 16]               0\n",
            "          Conv2d-127           [-1, 48, 16, 16]           8,640\n",
            "     BatchNorm2d-128           [-1, 48, 16, 16]              96\n",
            "            ReLU-129           [-1, 48, 16, 16]               0\n",
            "          Conv2d-130           [-1, 12, 16, 16]           5,184\n",
            " BottleneckBlock-131          [-1, 192, 16, 16]               0\n",
            "     BatchNorm2d-132          [-1, 192, 16, 16]             384\n",
            "            ReLU-133          [-1, 192, 16, 16]               0\n",
            "          Conv2d-134           [-1, 96, 16, 16]          18,432\n",
            " TransitionBlock-135             [-1, 96, 8, 8]               0\n",
            "     BatchNorm2d-136             [-1, 96, 8, 8]             192\n",
            "            ReLU-137             [-1, 96, 8, 8]               0\n",
            "          Conv2d-138             [-1, 48, 8, 8]           4,608\n",
            "     BatchNorm2d-139             [-1, 48, 8, 8]              96\n",
            "            ReLU-140             [-1, 48, 8, 8]               0\n",
            "          Conv2d-141             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-142            [-1, 108, 8, 8]               0\n",
            "     BatchNorm2d-143            [-1, 108, 8, 8]             216\n",
            "            ReLU-144            [-1, 108, 8, 8]               0\n",
            "          Conv2d-145             [-1, 48, 8, 8]           5,184\n",
            "     BatchNorm2d-146             [-1, 48, 8, 8]              96\n",
            "            ReLU-147             [-1, 48, 8, 8]               0\n",
            "          Conv2d-148             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-149            [-1, 120, 8, 8]               0\n",
            "     BatchNorm2d-150            [-1, 120, 8, 8]             240\n",
            "            ReLU-151            [-1, 120, 8, 8]               0\n",
            "          Conv2d-152             [-1, 48, 8, 8]           5,760\n",
            "     BatchNorm2d-153             [-1, 48, 8, 8]              96\n",
            "            ReLU-154             [-1, 48, 8, 8]               0\n",
            "          Conv2d-155             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-156            [-1, 132, 8, 8]               0\n",
            "     BatchNorm2d-157            [-1, 132, 8, 8]             264\n",
            "            ReLU-158            [-1, 132, 8, 8]               0\n",
            "          Conv2d-159             [-1, 48, 8, 8]           6,336\n",
            "     BatchNorm2d-160             [-1, 48, 8, 8]              96\n",
            "            ReLU-161             [-1, 48, 8, 8]               0\n",
            "          Conv2d-162             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-163            [-1, 144, 8, 8]               0\n",
            "     BatchNorm2d-164            [-1, 144, 8, 8]             288\n",
            "            ReLU-165            [-1, 144, 8, 8]               0\n",
            "          Conv2d-166             [-1, 48, 8, 8]           6,912\n",
            "     BatchNorm2d-167             [-1, 48, 8, 8]              96\n",
            "            ReLU-168             [-1, 48, 8, 8]               0\n",
            "          Conv2d-169             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-170            [-1, 156, 8, 8]               0\n",
            "     BatchNorm2d-171            [-1, 156, 8, 8]             312\n",
            "            ReLU-172            [-1, 156, 8, 8]               0\n",
            "          Conv2d-173             [-1, 48, 8, 8]           7,488\n",
            "     BatchNorm2d-174             [-1, 48, 8, 8]              96\n",
            "            ReLU-175             [-1, 48, 8, 8]               0\n",
            "          Conv2d-176             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-177            [-1, 168, 8, 8]               0\n",
            "     BatchNorm2d-178            [-1, 168, 8, 8]             336\n",
            "            ReLU-179            [-1, 168, 8, 8]               0\n",
            "          Conv2d-180             [-1, 48, 8, 8]           8,064\n",
            "     BatchNorm2d-181             [-1, 48, 8, 8]              96\n",
            "            ReLU-182             [-1, 48, 8, 8]               0\n",
            "          Conv2d-183             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-184            [-1, 180, 8, 8]               0\n",
            "     BatchNorm2d-185            [-1, 180, 8, 8]             360\n",
            "            ReLU-186            [-1, 180, 8, 8]               0\n",
            "          Conv2d-187             [-1, 48, 8, 8]           8,640\n",
            "     BatchNorm2d-188             [-1, 48, 8, 8]              96\n",
            "            ReLU-189             [-1, 48, 8, 8]               0\n",
            "          Conv2d-190             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-191            [-1, 192, 8, 8]               0\n",
            "     BatchNorm2d-192            [-1, 192, 8, 8]             384\n",
            "            ReLU-193            [-1, 192, 8, 8]               0\n",
            "          Conv2d-194             [-1, 48, 8, 8]           9,216\n",
            "     BatchNorm2d-195             [-1, 48, 8, 8]              96\n",
            "            ReLU-196             [-1, 48, 8, 8]               0\n",
            "          Conv2d-197             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-198            [-1, 204, 8, 8]               0\n",
            "     BatchNorm2d-199            [-1, 204, 8, 8]             408\n",
            "            ReLU-200            [-1, 204, 8, 8]               0\n",
            "          Conv2d-201             [-1, 48, 8, 8]           9,792\n",
            "     BatchNorm2d-202             [-1, 48, 8, 8]              96\n",
            "            ReLU-203             [-1, 48, 8, 8]               0\n",
            "          Conv2d-204             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-205            [-1, 216, 8, 8]               0\n",
            "     BatchNorm2d-206            [-1, 216, 8, 8]             432\n",
            "            ReLU-207            [-1, 216, 8, 8]               0\n",
            "          Conv2d-208             [-1, 48, 8, 8]          10,368\n",
            "     BatchNorm2d-209             [-1, 48, 8, 8]              96\n",
            "            ReLU-210             [-1, 48, 8, 8]               0\n",
            "          Conv2d-211             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-212            [-1, 228, 8, 8]               0\n",
            "     BatchNorm2d-213            [-1, 228, 8, 8]             456\n",
            "            ReLU-214            [-1, 228, 8, 8]               0\n",
            "          Conv2d-215             [-1, 48, 8, 8]          10,944\n",
            "     BatchNorm2d-216             [-1, 48, 8, 8]              96\n",
            "            ReLU-217             [-1, 48, 8, 8]               0\n",
            "          Conv2d-218             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-219            [-1, 240, 8, 8]               0\n",
            "     BatchNorm2d-220            [-1, 240, 8, 8]             480\n",
            "            ReLU-221            [-1, 240, 8, 8]               0\n",
            "          Conv2d-222             [-1, 48, 8, 8]          11,520\n",
            "     BatchNorm2d-223             [-1, 48, 8, 8]              96\n",
            "            ReLU-224             [-1, 48, 8, 8]               0\n",
            "          Conv2d-225             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-226            [-1, 252, 8, 8]               0\n",
            "     BatchNorm2d-227            [-1, 252, 8, 8]             504\n",
            "            ReLU-228            [-1, 252, 8, 8]               0\n",
            "          Conv2d-229             [-1, 48, 8, 8]          12,096\n",
            "     BatchNorm2d-230             [-1, 48, 8, 8]              96\n",
            "            ReLU-231             [-1, 48, 8, 8]               0\n",
            "          Conv2d-232             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-233            [-1, 264, 8, 8]               0\n",
            "     BatchNorm2d-234            [-1, 264, 8, 8]             528\n",
            "            ReLU-235            [-1, 264, 8, 8]               0\n",
            "          Conv2d-236             [-1, 48, 8, 8]          12,672\n",
            "     BatchNorm2d-237             [-1, 48, 8, 8]              96\n",
            "            ReLU-238             [-1, 48, 8, 8]               0\n",
            "          Conv2d-239             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-240            [-1, 276, 8, 8]               0\n",
            "     BatchNorm2d-241            [-1, 276, 8, 8]             552\n",
            "            ReLU-242            [-1, 276, 8, 8]               0\n",
            "          Conv2d-243             [-1, 48, 8, 8]          13,248\n",
            "     BatchNorm2d-244             [-1, 48, 8, 8]              96\n",
            "            ReLU-245             [-1, 48, 8, 8]               0\n",
            "          Conv2d-246             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-247            [-1, 288, 8, 8]               0\n",
            "     BatchNorm2d-248            [-1, 288, 8, 8]             576\n",
            "            ReLU-249            [-1, 288, 8, 8]               0\n",
            "          Conv2d-250             [-1, 48, 8, 8]          13,824\n",
            "     BatchNorm2d-251             [-1, 48, 8, 8]              96\n",
            "            ReLU-252             [-1, 48, 8, 8]               0\n",
            "          Conv2d-253             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-254            [-1, 300, 8, 8]               0\n",
            "     BatchNorm2d-255            [-1, 300, 8, 8]             600\n",
            "            ReLU-256            [-1, 300, 8, 8]               0\n",
            "          Conv2d-257             [-1, 48, 8, 8]          14,400\n",
            "     BatchNorm2d-258             [-1, 48, 8, 8]              96\n",
            "            ReLU-259             [-1, 48, 8, 8]               0\n",
            "          Conv2d-260             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-261            [-1, 312, 8, 8]               0\n",
            "     BatchNorm2d-262            [-1, 312, 8, 8]             624\n",
            "            ReLU-263            [-1, 312, 8, 8]               0\n",
            "          Conv2d-264             [-1, 48, 8, 8]          14,976\n",
            "     BatchNorm2d-265             [-1, 48, 8, 8]              96\n",
            "            ReLU-266             [-1, 48, 8, 8]               0\n",
            "          Conv2d-267             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-268            [-1, 324, 8, 8]               0\n",
            "     BatchNorm2d-269            [-1, 324, 8, 8]             648\n",
            "            ReLU-270            [-1, 324, 8, 8]               0\n",
            "          Conv2d-271             [-1, 48, 8, 8]          15,552\n",
            "     BatchNorm2d-272             [-1, 48, 8, 8]              96\n",
            "            ReLU-273             [-1, 48, 8, 8]               0\n",
            "          Conv2d-274             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-275            [-1, 336, 8, 8]               0\n",
            "     BatchNorm2d-276            [-1, 336, 8, 8]             672\n",
            "            ReLU-277            [-1, 336, 8, 8]               0\n",
            "          Conv2d-278             [-1, 48, 8, 8]          16,128\n",
            "     BatchNorm2d-279             [-1, 48, 8, 8]              96\n",
            "            ReLU-280             [-1, 48, 8, 8]               0\n",
            "          Conv2d-281             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-282            [-1, 348, 8, 8]               0\n",
            "     BatchNorm2d-283            [-1, 348, 8, 8]             696\n",
            "            ReLU-284            [-1, 348, 8, 8]               0\n",
            "          Conv2d-285             [-1, 48, 8, 8]          16,704\n",
            "     BatchNorm2d-286             [-1, 48, 8, 8]              96\n",
            "            ReLU-287             [-1, 48, 8, 8]               0\n",
            "          Conv2d-288             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-289            [-1, 360, 8, 8]               0\n",
            "     BatchNorm2d-290            [-1, 360, 8, 8]             720\n",
            "            ReLU-291            [-1, 360, 8, 8]               0\n",
            "          Conv2d-292             [-1, 48, 8, 8]          17,280\n",
            "     BatchNorm2d-293             [-1, 48, 8, 8]              96\n",
            "            ReLU-294             [-1, 48, 8, 8]               0\n",
            "          Conv2d-295             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-296            [-1, 372, 8, 8]               0\n",
            "     BatchNorm2d-297            [-1, 372, 8, 8]             744\n",
            "            ReLU-298            [-1, 372, 8, 8]               0\n",
            "          Conv2d-299             [-1, 48, 8, 8]          17,856\n",
            "     BatchNorm2d-300             [-1, 48, 8, 8]              96\n",
            "            ReLU-301             [-1, 48, 8, 8]               0\n",
            "          Conv2d-302             [-1, 12, 8, 8]           5,184\n",
            " BottleneckBlock-303            [-1, 384, 8, 8]               0\n",
            "     BatchNorm2d-304            [-1, 384, 8, 8]             768\n",
            "            ReLU-305            [-1, 384, 8, 8]               0\n",
            "          Conv2d-306            [-1, 192, 8, 8]          73,728\n",
            " TransitionBlock-307            [-1, 192, 4, 4]               0\n",
            "     BatchNorm2d-308            [-1, 192, 4, 4]             384\n",
            "            ReLU-309            [-1, 192, 4, 4]               0\n",
            "          Conv2d-310             [-1, 48, 4, 4]           9,216\n",
            "     BatchNorm2d-311             [-1, 48, 4, 4]              96\n",
            "            ReLU-312             [-1, 48, 4, 4]               0\n",
            "          Conv2d-313             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-314            [-1, 204, 4, 4]               0\n",
            "     BatchNorm2d-315            [-1, 204, 4, 4]             408\n",
            "            ReLU-316            [-1, 204, 4, 4]               0\n",
            "          Conv2d-317             [-1, 48, 4, 4]           9,792\n",
            "     BatchNorm2d-318             [-1, 48, 4, 4]              96\n",
            "            ReLU-319             [-1, 48, 4, 4]               0\n",
            "          Conv2d-320             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-321            [-1, 216, 4, 4]               0\n",
            "     BatchNorm2d-322            [-1, 216, 4, 4]             432\n",
            "            ReLU-323            [-1, 216, 4, 4]               0\n",
            "          Conv2d-324             [-1, 48, 4, 4]          10,368\n",
            "     BatchNorm2d-325             [-1, 48, 4, 4]              96\n",
            "            ReLU-326             [-1, 48, 4, 4]               0\n",
            "          Conv2d-327             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-328            [-1, 228, 4, 4]               0\n",
            "     BatchNorm2d-329            [-1, 228, 4, 4]             456\n",
            "            ReLU-330            [-1, 228, 4, 4]               0\n",
            "          Conv2d-331             [-1, 48, 4, 4]          10,944\n",
            "     BatchNorm2d-332             [-1, 48, 4, 4]              96\n",
            "            ReLU-333             [-1, 48, 4, 4]               0\n",
            "          Conv2d-334             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-335            [-1, 240, 4, 4]               0\n",
            "     BatchNorm2d-336            [-1, 240, 4, 4]             480\n",
            "            ReLU-337            [-1, 240, 4, 4]               0\n",
            "          Conv2d-338             [-1, 48, 4, 4]          11,520\n",
            "     BatchNorm2d-339             [-1, 48, 4, 4]              96\n",
            "            ReLU-340             [-1, 48, 4, 4]               0\n",
            "          Conv2d-341             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-342            [-1, 252, 4, 4]               0\n",
            "     BatchNorm2d-343            [-1, 252, 4, 4]             504\n",
            "            ReLU-344            [-1, 252, 4, 4]               0\n",
            "          Conv2d-345             [-1, 48, 4, 4]          12,096\n",
            "     BatchNorm2d-346             [-1, 48, 4, 4]              96\n",
            "            ReLU-347             [-1, 48, 4, 4]               0\n",
            "          Conv2d-348             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-349            [-1, 264, 4, 4]               0\n",
            "     BatchNorm2d-350            [-1, 264, 4, 4]             528\n",
            "            ReLU-351            [-1, 264, 4, 4]               0\n",
            "          Conv2d-352             [-1, 48, 4, 4]          12,672\n",
            "     BatchNorm2d-353             [-1, 48, 4, 4]              96\n",
            "            ReLU-354             [-1, 48, 4, 4]               0\n",
            "          Conv2d-355             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-356            [-1, 276, 4, 4]               0\n",
            "     BatchNorm2d-357            [-1, 276, 4, 4]             552\n",
            "            ReLU-358            [-1, 276, 4, 4]               0\n",
            "          Conv2d-359             [-1, 48, 4, 4]          13,248\n",
            "     BatchNorm2d-360             [-1, 48, 4, 4]              96\n",
            "            ReLU-361             [-1, 48, 4, 4]               0\n",
            "          Conv2d-362             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-363            [-1, 288, 4, 4]               0\n",
            "     BatchNorm2d-364            [-1, 288, 4, 4]             576\n",
            "            ReLU-365            [-1, 288, 4, 4]               0\n",
            "          Conv2d-366             [-1, 48, 4, 4]          13,824\n",
            "     BatchNorm2d-367             [-1, 48, 4, 4]              96\n",
            "            ReLU-368             [-1, 48, 4, 4]               0\n",
            "          Conv2d-369             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-370            [-1, 300, 4, 4]               0\n",
            "     BatchNorm2d-371            [-1, 300, 4, 4]             600\n",
            "            ReLU-372            [-1, 300, 4, 4]               0\n",
            "          Conv2d-373             [-1, 48, 4, 4]          14,400\n",
            "     BatchNorm2d-374             [-1, 48, 4, 4]              96\n",
            "            ReLU-375             [-1, 48, 4, 4]               0\n",
            "          Conv2d-376             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-377            [-1, 312, 4, 4]               0\n",
            "     BatchNorm2d-378            [-1, 312, 4, 4]             624\n",
            "            ReLU-379            [-1, 312, 4, 4]               0\n",
            "          Conv2d-380             [-1, 48, 4, 4]          14,976\n",
            "     BatchNorm2d-381             [-1, 48, 4, 4]              96\n",
            "            ReLU-382             [-1, 48, 4, 4]               0\n",
            "          Conv2d-383             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-384            [-1, 324, 4, 4]               0\n",
            "     BatchNorm2d-385            [-1, 324, 4, 4]             648\n",
            "            ReLU-386            [-1, 324, 4, 4]               0\n",
            "          Conv2d-387             [-1, 48, 4, 4]          15,552\n",
            "     BatchNorm2d-388             [-1, 48, 4, 4]              96\n",
            "            ReLU-389             [-1, 48, 4, 4]               0\n",
            "          Conv2d-390             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-391            [-1, 336, 4, 4]               0\n",
            "     BatchNorm2d-392            [-1, 336, 4, 4]             672\n",
            "            ReLU-393            [-1, 336, 4, 4]               0\n",
            "          Conv2d-394             [-1, 48, 4, 4]          16,128\n",
            "     BatchNorm2d-395             [-1, 48, 4, 4]              96\n",
            "            ReLU-396             [-1, 48, 4, 4]               0\n",
            "          Conv2d-397             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-398            [-1, 348, 4, 4]               0\n",
            "     BatchNorm2d-399            [-1, 348, 4, 4]             696\n",
            "            ReLU-400            [-1, 348, 4, 4]               0\n",
            "          Conv2d-401             [-1, 48, 4, 4]          16,704\n",
            "     BatchNorm2d-402             [-1, 48, 4, 4]              96\n",
            "            ReLU-403             [-1, 48, 4, 4]               0\n",
            "          Conv2d-404             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-405            [-1, 360, 4, 4]               0\n",
            "     BatchNorm2d-406            [-1, 360, 4, 4]             720\n",
            "            ReLU-407            [-1, 360, 4, 4]               0\n",
            "          Conv2d-408             [-1, 48, 4, 4]          17,280\n",
            "     BatchNorm2d-409             [-1, 48, 4, 4]              96\n",
            "            ReLU-410             [-1, 48, 4, 4]               0\n",
            "          Conv2d-411             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-412            [-1, 372, 4, 4]               0\n",
            "     BatchNorm2d-413            [-1, 372, 4, 4]             744\n",
            "            ReLU-414            [-1, 372, 4, 4]               0\n",
            "          Conv2d-415             [-1, 48, 4, 4]          17,856\n",
            "     BatchNorm2d-416             [-1, 48, 4, 4]              96\n",
            "            ReLU-417             [-1, 48, 4, 4]               0\n",
            "          Conv2d-418             [-1, 12, 4, 4]           5,184\n",
            " BottleneckBlock-419            [-1, 384, 4, 4]               0\n",
            "     BatchNorm2d-420            [-1, 384, 4, 4]             768\n",
            "            ReLU-421            [-1, 384, 4, 4]               0\n",
            "          Linear-422                   [-1, 10]           3,850\n",
            "================================================================\n",
            "Total params: 1,000,618\n",
            "Trainable params: 1,000,618\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 43.32\n",
            "Params size (MB): 3.82\n",
            "Estimated Total Size (MB): 47.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGgpGhJ5NZSC"
      },
      "source": [
        "learning_rate = 0.1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec5MNSZ_nSRv"
      },
      "source": [
        "train_batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "best_valid_loss = 1024\n",
        "patience = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l-LNYOHMIkb",
        "outputId": "b5bba8d5-d289-488e-a4dd-bc50c04c065f"
      },
      "source": [
        "epochs = 200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        train_correct += predicted.eq(labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "    train_loss = train_loss / train_batches\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_loss = val_loss / val_batches\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        torch.save(model.state_dict(), './DenseNet_CIFAR10.pt')\n",
        "        best_valid_loss = val_loss\n",
        "        patience = 0\n",
        "    \n",
        "    print('[%d/%d] TrainLoss: %.3f, ValLoss: %.3f | TrainAcc: %.2f, ValAcc: %.2f'\\\n",
        "          % (epoch+1, epochs, train_loss, val_loss, train_acc, val_acc))\n",
        "    \n",
        "\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/200] TrainLoss: 1.504, ValLoss: 1.201 | TrainAcc: 0.45, ValAcc: 0.57\n",
            "[2/200] TrainLoss: 0.954, ValLoss: 0.798 | TrainAcc: 0.66, ValAcc: 0.71\n",
            "[3/200] TrainLoss: 0.697, ValLoss: 0.727 | TrainAcc: 0.76, ValAcc: 0.75\n",
            "[4/200] TrainLoss: 0.572, ValLoss: 0.764 | TrainAcc: 0.80, ValAcc: 0.73\n",
            "[5/200] TrainLoss: 0.507, ValLoss: 0.674 | TrainAcc: 0.82, ValAcc: 0.77\n",
            "[6/200] TrainLoss: 0.460, ValLoss: 0.561 | TrainAcc: 0.84, ValAcc: 0.81\n",
            "[7/200] TrainLoss: 0.430, ValLoss: 0.574 | TrainAcc: 0.85, ValAcc: 0.81\n",
            "[8/200] TrainLoss: 0.402, ValLoss: 0.568 | TrainAcc: 0.86, ValAcc: 0.80\n",
            "[9/200] TrainLoss: 0.388, ValLoss: 0.598 | TrainAcc: 0.87, ValAcc: 0.80\n",
            "[10/200] TrainLoss: 0.370, ValLoss: 0.548 | TrainAcc: 0.87, ValAcc: 0.81\n",
            "[11/200] TrainLoss: 0.361, ValLoss: 0.619 | TrainAcc: 0.87, ValAcc: 0.80\n",
            "[12/200] TrainLoss: 0.358, ValLoss: 0.499 | TrainAcc: 0.88, ValAcc: 0.84\n",
            "[13/200] TrainLoss: 0.343, ValLoss: 0.547 | TrainAcc: 0.88, ValAcc: 0.81\n",
            "[14/200] TrainLoss: 0.347, ValLoss: 0.696 | TrainAcc: 0.88, ValAcc: 0.77\n",
            "[15/200] TrainLoss: 0.341, ValLoss: 0.488 | TrainAcc: 0.88, ValAcc: 0.84\n",
            "[16/200] TrainLoss: 0.334, ValLoss: 0.570 | TrainAcc: 0.88, ValAcc: 0.81\n",
            "[17/200] TrainLoss: 0.327, ValLoss: 0.507 | TrainAcc: 0.89, ValAcc: 0.83\n",
            "[18/200] TrainLoss: 0.323, ValLoss: 0.606 | TrainAcc: 0.89, ValAcc: 0.81\n",
            "[19/200] TrainLoss: 0.321, ValLoss: 0.537 | TrainAcc: 0.89, ValAcc: 0.82\n",
            "[20/200] TrainLoss: 0.315, ValLoss: 0.549 | TrainAcc: 0.89, ValAcc: 0.82\n",
            "[21/200] TrainLoss: 0.314, ValLoss: 0.540 | TrainAcc: 0.89, ValAcc: 0.82\n",
            "[22/200] TrainLoss: 0.305, ValLoss: 0.577 | TrainAcc: 0.89, ValAcc: 0.81\n",
            "[23/200] TrainLoss: 0.303, ValLoss: 0.610 | TrainAcc: 0.89, ValAcc: 0.81\n",
            "[24/200] TrainLoss: 0.294, ValLoss: 0.594 | TrainAcc: 0.90, ValAcc: 0.82\n",
            "[25/200] TrainLoss: 0.306, ValLoss: 0.458 | TrainAcc: 0.89, ValAcc: 0.84\n",
            "[26/200] TrainLoss: 0.293, ValLoss: 0.621 | TrainAcc: 0.90, ValAcc: 0.81\n",
            "[27/200] TrainLoss: 0.291, ValLoss: 0.610 | TrainAcc: 0.90, ValAcc: 0.80\n",
            "[28/200] TrainLoss: 0.287, ValLoss: 0.470 | TrainAcc: 0.90, ValAcc: 0.84\n",
            "[29/200] TrainLoss: 0.286, ValLoss: 0.523 | TrainAcc: 0.90, ValAcc: 0.83\n",
            "[30/200] TrainLoss: 0.281, ValLoss: 0.544 | TrainAcc: 0.90, ValAcc: 0.82\n",
            "[31/200] TrainLoss: 0.284, ValLoss: 0.462 | TrainAcc: 0.90, ValAcc: 0.85\n",
            "[32/200] TrainLoss: 0.276, ValLoss: 0.519 | TrainAcc: 0.90, ValAcc: 0.83\n",
            "[33/200] TrainLoss: 0.272, ValLoss: 0.442 | TrainAcc: 0.90, ValAcc: 0.86\n",
            "[34/200] TrainLoss: 0.273, ValLoss: 0.543 | TrainAcc: 0.90, ValAcc: 0.82\n",
            "[35/200] TrainLoss: 0.267, ValLoss: 0.510 | TrainAcc: 0.91, ValAcc: 0.83\n",
            "[36/200] TrainLoss: 0.267, ValLoss: 0.581 | TrainAcc: 0.91, ValAcc: 0.82\n",
            "[37/200] TrainLoss: 0.261, ValLoss: 0.563 | TrainAcc: 0.91, ValAcc: 0.81\n",
            "[38/200] TrainLoss: 0.263, ValLoss: 0.512 | TrainAcc: 0.91, ValAcc: 0.84\n",
            "[39/200] TrainLoss: 0.261, ValLoss: 0.819 | TrainAcc: 0.91, ValAcc: 0.76\n",
            "[40/200] TrainLoss: 0.254, ValLoss: 0.563 | TrainAcc: 0.91, ValAcc: 0.82\n",
            "[41/200] TrainLoss: 0.259, ValLoss: 0.560 | TrainAcc: 0.91, ValAcc: 0.81\n",
            "[42/200] TrainLoss: 0.251, ValLoss: 0.509 | TrainAcc: 0.91, ValAcc: 0.84\n",
            "[43/200] TrainLoss: 0.258, ValLoss: 0.592 | TrainAcc: 0.91, ValAcc: 0.82\n",
            "[44/200] TrainLoss: 0.246, ValLoss: 0.483 | TrainAcc: 0.91, ValAcc: 0.85\n",
            "[45/200] TrainLoss: 0.245, ValLoss: 0.478 | TrainAcc: 0.91, ValAcc: 0.83\n",
            "[46/200] TrainLoss: 0.238, ValLoss: 0.626 | TrainAcc: 0.92, ValAcc: 0.81\n",
            "[47/200] TrainLoss: 0.243, ValLoss: 0.486 | TrainAcc: 0.91, ValAcc: 0.85\n",
            "[48/200] TrainLoss: 0.246, ValLoss: 0.486 | TrainAcc: 0.91, ValAcc: 0.84\n",
            "[49/200] TrainLoss: 0.238, ValLoss: 0.454 | TrainAcc: 0.92, ValAcc: 0.85\n",
            "[50/200] TrainLoss: 0.235, ValLoss: 0.508 | TrainAcc: 0.92, ValAcc: 0.84\n",
            "[51/200] TrainLoss: 0.235, ValLoss: 0.577 | TrainAcc: 0.92, ValAcc: 0.83\n",
            "[52/200] TrainLoss: 0.232, ValLoss: 0.492 | TrainAcc: 0.92, ValAcc: 0.84\n",
            "[53/200] TrainLoss: 0.238, ValLoss: 0.754 | TrainAcc: 0.92, ValAcc: 0.78\n",
            "[54/200] TrainLoss: 0.227, ValLoss: 0.504 | TrainAcc: 0.92, ValAcc: 0.84\n",
            "[55/200] TrainLoss: 0.229, ValLoss: 0.596 | TrainAcc: 0.92, ValAcc: 0.82\n",
            "[56/200] TrainLoss: 0.232, ValLoss: 0.535 | TrainAcc: 0.92, ValAcc: 0.83\n",
            "[57/200] TrainLoss: 0.222, ValLoss: 0.468 | TrainAcc: 0.92, ValAcc: 0.85\n",
            "[58/200] TrainLoss: 0.219, ValLoss: 0.546 | TrainAcc: 0.92, ValAcc: 0.83\n",
            "[59/200] TrainLoss: 0.217, ValLoss: 0.429 | TrainAcc: 0.92, ValAcc: 0.86\n",
            "[60/200] TrainLoss: 0.219, ValLoss: 0.711 | TrainAcc: 0.92, ValAcc: 0.79\n",
            "[61/200] TrainLoss: 0.212, ValLoss: 0.501 | TrainAcc: 0.93, ValAcc: 0.84\n",
            "[62/200] TrainLoss: 0.219, ValLoss: 0.815 | TrainAcc: 0.92, ValAcc: 0.77\n",
            "[63/200] TrainLoss: 0.205, ValLoss: 0.490 | TrainAcc: 0.93, ValAcc: 0.84\n",
            "[64/200] TrainLoss: 0.208, ValLoss: 0.507 | TrainAcc: 0.93, ValAcc: 0.83\n",
            "[65/200] TrainLoss: 0.211, ValLoss: 0.507 | TrainAcc: 0.93, ValAcc: 0.85\n",
            "[66/200] TrainLoss: 0.206, ValLoss: 0.747 | TrainAcc: 0.93, ValAcc: 0.78\n",
            "[67/200] TrainLoss: 0.200, ValLoss: 0.561 | TrainAcc: 0.93, ValAcc: 0.83\n",
            "[68/200] TrainLoss: 0.198, ValLoss: 0.482 | TrainAcc: 0.93, ValAcc: 0.84\n",
            "[69/200] TrainLoss: 0.204, ValLoss: 0.536 | TrainAcc: 0.93, ValAcc: 0.83\n",
            "[70/200] TrainLoss: 0.192, ValLoss: 0.705 | TrainAcc: 0.93, ValAcc: 0.79\n",
            "[71/200] TrainLoss: 0.192, ValLoss: 0.557 | TrainAcc: 0.93, ValAcc: 0.82\n",
            "[72/200] TrainLoss: 0.187, ValLoss: 0.517 | TrainAcc: 0.94, ValAcc: 0.85\n",
            "[73/200] TrainLoss: 0.188, ValLoss: 0.575 | TrainAcc: 0.93, ValAcc: 0.82\n",
            "[74/200] TrainLoss: 0.184, ValLoss: 0.411 | TrainAcc: 0.94, ValAcc: 0.87\n",
            "[75/200] TrainLoss: 0.184, ValLoss: 0.473 | TrainAcc: 0.94, ValAcc: 0.85\n",
            "[76/200] TrainLoss: 0.185, ValLoss: 0.515 | TrainAcc: 0.94, ValAcc: 0.85\n",
            "[77/200] TrainLoss: 0.180, ValLoss: 0.549 | TrainAcc: 0.94, ValAcc: 0.84\n",
            "[78/200] TrainLoss: 0.179, ValLoss: 0.555 | TrainAcc: 0.94, ValAcc: 0.83\n",
            "[79/200] TrainLoss: 0.173, ValLoss: 0.556 | TrainAcc: 0.94, ValAcc: 0.84\n",
            "[80/200] TrainLoss: 0.179, ValLoss: 0.491 | TrainAcc: 0.94, ValAcc: 0.85\n",
            "[81/200] TrainLoss: 0.174, ValLoss: 0.442 | TrainAcc: 0.94, ValAcc: 0.86\n",
            "[82/200] TrainLoss: 0.165, ValLoss: 0.573 | TrainAcc: 0.94, ValAcc: 0.83\n",
            "[83/200] TrainLoss: 0.168, ValLoss: 0.570 | TrainAcc: 0.94, ValAcc: 0.82\n",
            "[84/200] TrainLoss: 0.157, ValLoss: 0.562 | TrainAcc: 0.95, ValAcc: 0.83\n",
            "[85/200] TrainLoss: 0.156, ValLoss: 0.546 | TrainAcc: 0.95, ValAcc: 0.84\n",
            "[86/200] TrainLoss: 0.162, ValLoss: 0.481 | TrainAcc: 0.94, ValAcc: 0.86\n",
            "[87/200] TrainLoss: 0.151, ValLoss: 0.436 | TrainAcc: 0.95, ValAcc: 0.86\n",
            "[88/200] TrainLoss: 0.164, ValLoss: 0.447 | TrainAcc: 0.94, ValAcc: 0.86\n",
            "[89/200] TrainLoss: 0.149, ValLoss: 0.542 | TrainAcc: 0.95, ValAcc: 0.84\n",
            "[90/200] TrainLoss: 0.146, ValLoss: 0.486 | TrainAcc: 0.95, ValAcc: 0.86\n",
            "[91/200] TrainLoss: 0.155, ValLoss: 0.542 | TrainAcc: 0.94, ValAcc: 0.83\n",
            "[92/200] TrainLoss: 0.142, ValLoss: 0.489 | TrainAcc: 0.95, ValAcc: 0.85\n",
            "[93/200] TrainLoss: 0.143, ValLoss: 0.474 | TrainAcc: 0.95, ValAcc: 0.86\n",
            "[94/200] TrainLoss: 0.139, ValLoss: 0.506 | TrainAcc: 0.95, ValAcc: 0.84\n",
            "[95/200] TrainLoss: 0.137, ValLoss: 0.499 | TrainAcc: 0.95, ValAcc: 0.85\n",
            "[96/200] TrainLoss: 0.129, ValLoss: 0.483 | TrainAcc: 0.96, ValAcc: 0.86\n",
            "[97/200] TrainLoss: 0.134, ValLoss: 0.472 | TrainAcc: 0.95, ValAcc: 0.86\n",
            "[98/200] TrainLoss: 0.132, ValLoss: 0.640 | TrainAcc: 0.95, ValAcc: 0.82\n",
            "[99/200] TrainLoss: 0.130, ValLoss: 0.510 | TrainAcc: 0.96, ValAcc: 0.85\n",
            "[100/200] TrainLoss: 0.119, ValLoss: 0.467 | TrainAcc: 0.96, ValAcc: 0.86\n",
            "[101/200] TrainLoss: 0.123, ValLoss: 0.539 | TrainAcc: 0.96, ValAcc: 0.84\n",
            "[102/200] TrainLoss: 0.122, ValLoss: 0.501 | TrainAcc: 0.96, ValAcc: 0.85\n",
            "[103/200] TrainLoss: 0.116, ValLoss: 0.483 | TrainAcc: 0.96, ValAcc: 0.86\n",
            "[104/200] TrainLoss: 0.113, ValLoss: 0.518 | TrainAcc: 0.96, ValAcc: 0.85\n",
            "[105/200] TrainLoss: 0.111, ValLoss: 0.462 | TrainAcc: 0.96, ValAcc: 0.86\n",
            "[106/200] TrainLoss: 0.108, ValLoss: 0.416 | TrainAcc: 0.96, ValAcc: 0.88\n",
            "[107/200] TrainLoss: 0.109, ValLoss: 0.582 | TrainAcc: 0.96, ValAcc: 0.84\n",
            "[108/200] TrainLoss: 0.101, ValLoss: 0.553 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[109/200] TrainLoss: 0.104, ValLoss: 0.483 | TrainAcc: 0.96, ValAcc: 0.85\n",
            "[110/200] TrainLoss: 0.105, ValLoss: 0.467 | TrainAcc: 0.96, ValAcc: 0.86\n",
            "[111/200] TrainLoss: 0.085, ValLoss: 0.529 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[112/200] TrainLoss: 0.094, ValLoss: 0.447 | TrainAcc: 0.97, ValAcc: 0.87\n",
            "[113/200] TrainLoss: 0.086, ValLoss: 0.543 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[114/200] TrainLoss: 0.091, ValLoss: 0.539 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[115/200] TrainLoss: 0.089, ValLoss: 0.602 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[116/200] TrainLoss: 0.097, ValLoss: 0.539 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[117/200] TrainLoss: 0.079, ValLoss: 0.555 | TrainAcc: 0.97, ValAcc: 0.85\n",
            "[118/200] TrainLoss: 0.076, ValLoss: 0.466 | TrainAcc: 0.97, ValAcc: 0.86\n",
            "[119/200] TrainLoss: 0.085, ValLoss: 0.668 | TrainAcc: 0.97, ValAcc: 0.81\n",
            "[120/200] TrainLoss: 0.078, ValLoss: 0.457 | TrainAcc: 0.97, ValAcc: 0.87\n",
            "[121/200] TrainLoss: 0.070, ValLoss: 0.506 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[122/200] TrainLoss: 0.064, ValLoss: 0.514 | TrainAcc: 0.98, ValAcc: 0.86\n",
            "[123/200] TrainLoss: 0.072, ValLoss: 0.475 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[124/200] TrainLoss: 0.075, ValLoss: 0.449 | TrainAcc: 0.97, ValAcc: 0.87\n",
            "[125/200] TrainLoss: 0.056, ValLoss: 0.454 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[126/200] TrainLoss: 0.058, ValLoss: 0.462 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[127/200] TrainLoss: 0.065, ValLoss: 0.431 | TrainAcc: 0.98, ValAcc: 0.88\n",
            "[128/200] TrainLoss: 0.051, ValLoss: 0.486 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[129/200] TrainLoss: 0.045, ValLoss: 0.464 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[130/200] TrainLoss: 0.048, ValLoss: 0.472 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[131/200] TrainLoss: 0.055, ValLoss: 0.547 | TrainAcc: 0.98, ValAcc: 0.85\n",
            "[132/200] TrainLoss: 0.053, ValLoss: 0.475 | TrainAcc: 0.98, ValAcc: 0.87\n",
            "[133/200] TrainLoss: 0.047, ValLoss: 0.576 | TrainAcc: 0.99, ValAcc: 0.86\n",
            "[134/200] TrainLoss: 0.049, ValLoss: 0.447 | TrainAcc: 0.98, ValAcc: 0.88\n",
            "[135/200] TrainLoss: 0.044, ValLoss: 0.456 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[136/200] TrainLoss: 0.043, ValLoss: 0.505 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[137/200] TrainLoss: 0.039, ValLoss: 0.454 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[138/200] TrainLoss: 0.027, ValLoss: 0.493 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[139/200] TrainLoss: 0.036, ValLoss: 0.472 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[140/200] TrainLoss: 0.025, ValLoss: 0.367 | TrainAcc: 0.99, ValAcc: 0.90\n",
            "[141/200] TrainLoss: 0.021, ValLoss: 0.432 | TrainAcc: 0.99, ValAcc: 0.89\n",
            "[142/200] TrainLoss: 0.023, ValLoss: 0.507 | TrainAcc: 0.99, ValAcc: 0.87\n",
            "[143/200] TrainLoss: 0.028, ValLoss: 0.461 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[144/200] TrainLoss: 0.033, ValLoss: 0.551 | TrainAcc: 0.99, ValAcc: 0.86\n",
            "[145/200] TrainLoss: 0.042, ValLoss: 0.458 | TrainAcc: 0.99, ValAcc: 0.88\n",
            "[146/200] TrainLoss: 0.021, ValLoss: 0.397 | TrainAcc: 0.99, ValAcc: 0.90\n",
            "[147/200] TrainLoss: 0.013, ValLoss: 0.381 | TrainAcc: 1.00, ValAcc: 0.90\n",
            "[148/200] TrainLoss: 0.005, ValLoss: 0.372 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[149/200] TrainLoss: 0.004, ValLoss: 0.360 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[150/200] TrainLoss: 0.003, ValLoss: 0.342 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[151/200] TrainLoss: 0.002, ValLoss: 0.341 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[152/200] TrainLoss: 0.001, ValLoss: 0.324 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[153/200] TrainLoss: 0.001, ValLoss: 0.319 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[154/200] TrainLoss: 0.001, ValLoss: 0.315 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[155/200] TrainLoss: 0.001, ValLoss: 0.319 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[156/200] TrainLoss: 0.001, ValLoss: 0.335 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[157/200] TrainLoss: 0.001, ValLoss: 0.331 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[158/200] TrainLoss: 0.001, ValLoss: 0.323 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[159/200] TrainLoss: 0.001, ValLoss: 0.311 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[160/200] TrainLoss: 0.001, ValLoss: 0.316 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[161/200] TrainLoss: 0.001, ValLoss: 0.318 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[162/200] TrainLoss: 0.002, ValLoss: 0.320 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[163/200] TrainLoss: 0.002, ValLoss: 0.326 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[164/200] TrainLoss: 0.001, ValLoss: 0.323 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[165/200] TrainLoss: 0.002, ValLoss: 0.349 | TrainAcc: 1.00, ValAcc: 0.92\n",
            "[166/200] TrainLoss: 0.002, ValLoss: 0.325 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[167/200] TrainLoss: 0.002, ValLoss: 0.328 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[168/200] TrainLoss: 0.002, ValLoss: 0.330 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[169/200] TrainLoss: 0.002, ValLoss: 0.350 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[170/200] TrainLoss: 0.003, ValLoss: 0.375 | TrainAcc: 1.00, ValAcc: 0.90\n",
            "[171/200] TrainLoss: 0.005, ValLoss: 0.389 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[172/200] TrainLoss: 0.008, ValLoss: 0.461 | TrainAcc: 1.00, ValAcc: 0.89\n",
            "[173/200] TrainLoss: 0.006, ValLoss: 0.377 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[174/200] TrainLoss: 0.004, ValLoss: 0.370 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[175/200] TrainLoss: 0.003, ValLoss: 0.358 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[176/200] TrainLoss: 0.002, ValLoss: 0.366 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[177/200] TrainLoss: 0.002, ValLoss: 0.370 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[178/200] TrainLoss: 0.002, ValLoss: 0.378 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[179/200] TrainLoss: 0.002, ValLoss: 0.365 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[180/200] TrainLoss: 0.002, ValLoss: 0.380 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[181/200] TrainLoss: 0.002, ValLoss: 0.374 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[182/200] TrainLoss: 0.002, ValLoss: 0.370 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[183/200] TrainLoss: 0.002, ValLoss: 0.375 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[184/200] TrainLoss: 0.002, ValLoss: 0.386 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[185/200] TrainLoss: 0.002, ValLoss: 0.377 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[186/200] TrainLoss: 0.002, ValLoss: 0.366 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[187/200] TrainLoss: 0.002, ValLoss: 0.367 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[188/200] TrainLoss: 0.002, ValLoss: 0.382 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[189/200] TrainLoss: 0.001, ValLoss: 0.381 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[190/200] TrainLoss: 0.001, ValLoss: 0.367 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[191/200] TrainLoss: 0.001, ValLoss: 0.364 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[192/200] TrainLoss: 0.001, ValLoss: 0.379 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[193/200] TrainLoss: 0.001, ValLoss: 0.372 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[194/200] TrainLoss: 0.002, ValLoss: 0.368 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[195/200] TrainLoss: 0.001, ValLoss: 0.402 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[196/200] TrainLoss: 0.001, ValLoss: 0.378 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[197/200] TrainLoss: 0.002, ValLoss: 0.366 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[198/200] TrainLoss: 0.001, ValLoss: 0.371 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[199/200] TrainLoss: 0.001, ValLoss: 0.375 | TrainAcc: 1.00, ValAcc: 0.91\n",
            "[200/200] TrainLoss: 0.002, ValLoss: 0.391 | TrainAcc: 1.00, ValAcc: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VTizpoQdsZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otyrxXhVjmSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6b741046-9765-454f-85b7-75109a93bcd4"
      },
      "source": [
        "files.download('./DenseNet_CIFAR10.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_82edf212-c544-46a6-8033-bb0e12fe7f96\", \"2018312292_DongwonKim.pt\", 4358557)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}